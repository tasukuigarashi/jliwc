% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenize_mecab.R
\name{tokenize_mecab}
\alias{tokenize_mecab}
\title{Word segmentation using MeCab}
\usage{
tokenize_mecab(
  text,
  text_field = "text",
  sys_dic = getOption("jliwc_IPADIC"),
  user_dic = getOption("jliwc_USERDIC"),
  original = FALSE,
  liwclike = TRUE
)
}
\arguments{
\item{text}{A character vector. If a data frame is given,
the function will use the column specified by \code{text_field}.}

\item{text_field}{A character vector. By default, the column name of \code{text} to be used.}

\item{sys_dic}{A character vector. The location of the system dictionary of MeCab.}

\item{user_dic}{A character vector. The location of the user dictionary of MeCab.}

\item{original}{A logical value. If \code{TRUE}, the function will use the original form of words.
For example, '思い' is transformed into the original form of '思う'. This is useful for
counting words.}

\item{liwclike}{A logical value. If \code{TRUE},
the function will exclude delimiters (\code{'\b'}) according to LIWC2015.}
}
\value{
A data frame
}
\description{
Segments Japanese text into words using MeCab.
}
\examples{
\dontrun{
load_dictionaries()

# Word segmentation
gibasa::ginga[10:20] |> tokenize_mecab()

# Use original form of words
gibasa::ginga[10:20] |>
  tokenize_mecab(original = TRUE) |>
  dplyr::select(token, Original)
}

}
